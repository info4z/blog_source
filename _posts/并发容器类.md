---
title: 并发容器类
excerpt: 容器主要就分类单列和双列两种, 掌握Map是重中之重
date: 2020-05-22
categories: 高性能编程
tags: [多线程并发编程, J.U.C并发编程包]
---





## 一 : 学习方法

**逻辑思维能力是梳理学习方法的基础**; 养成线程思维: 两个或者多个给概念,像一条线串起来

首先要经过**演绎推导法**进行**因果推理**; 比如java中网络编程只提供了BIO和NIO两种方式, 所以一切框架中, 涉及到网络处理的, 都可以用这两个知识点去探究原理

然后采用**归纳总结法**提出可能正确的**猜想**; 比如线上10台服务器, 有三台总是每天会自动重启, 收集相关信息后, 发现是运维在修改监控系统配置的时候, 漏掉了提高这三台服务器的重启阈值

最后要使用**类比法**进行思维固化; 比如**集群**概念就好像是马在拉车,一匹马拉不动的时候,就是用多匹马去拉; **分布式**的概念, 就像是理发的过程中, 洗头发和剪头发是不同的人负责的

## 二 : 推理 HashMap 的实现

数据要存储

* 涉及到数据结构 : **数组**, **链表**, **栈**, **树**, **队列**

数组的插入和查找
- **顺序查找 :** 插入时按先后顺序插入, 查找时轮询扫描进行对比
- **二分查找 :** 插入时进行排序; 查找时将 n 个元素分成大致相等的两部分, 减少复杂度
- **分块查找 :** 分块查找是二分查找和顺序查找的一种改进
- **哈希表 :** 对元素的关键信息进行 hash 计算, 求出下标后直接插入或查找; 常用的实现是除留余数法

哈希冲突, 数组位置已存在值

- hash(key2) = hash(key1); 链地址法; ReHash1(key2) 再次计算 hash;

合理控制数组和链表的长度

- 动态扩容 resize()

## 三 : HashMap

jdk1.7:
- 数据结构 : 数组 + 链表, Entry<K,V>[] table;
- 实现原理 : 计算key的hash值,然后根据数组长度进行除留余数法确定数组位置; 如果是存入,先判定key存在不存在,若存在覆盖value的值;若不存在,则放在链表的最后, 如果是读取采用顺序查找法进行比对
- 扩容规则 : 初始容量 16, 扩容因子 0.75;
  1. 如果有初始长度, 则会以最靠近指定长度的2的幂次进行定容,例如: 519则会定为1024
  2. 如果储存的值超过容量的 0.75 倍, 以 2 倍方式进行扩容, 存储的元素会重新排列

jdk1.8:
- 数据结构: Node<K,V>[] table; 别以为有啥变化, Node 和 Entry 结构一样; 在jdk1.7的基础上进行了改进,在数据结构上引入了树形结构
- 链表阈值8, 最小容量 64
  1. 如果单个链表容量超过 8, 该链表则自动转为红黑树
  2. 如果链表达到8, 但是数组没有超过 64, 只会 resize 而不会生成树
- 由于有扩容机制的存在, 所以用到红黑树的概率很低, 同时, 维护树也是对性能的消耗

## 四 : ConcurrentHashMap

jdk1.7
- 数据结构 : Segment<K,V>[] segments;
  - Segment是个啥? 每个存储单元称为segment, 结构上没有任何区别, 但是它继承了ReentrantLock, 每个segment中包含一个 HashEntry[]
  - 那HashEntry又是个啥? 主要包含hash值, key, value 和 next, 就是HashMap中的Entry呀! 那 Segment 不就是个map吗, 也就是说每个 segment 就是一个 HashMap
- 设计原理 :
  - 也就是说 ConcurrentHashMap 不能扩容,但是 Segment 可以扩容
  - 这不是有病吗? 这设计太鬼才了! 是否会存在设计过度的嫌疑, 我感觉有点绕弯; Segment 的数量定死就是16个,还高大上的起了个名字叫**分段锁**, 但实质上也就只能支持16个并发量
  - 既然是为了提高并发操作的安全性, 那我为什么不在每个 HashMap 中的每个 Entry 上加一把锁呢
- 扩容规则 : 和 HashMap 稍微有些区别, 数组的容量是固定的16个

jdk1.8
- 数据结构 : Node<K,V> table; 数组 + 链表
- 初始容量16, 扩容银子 0.75, 阈值也是 8, 最小容量 64
- 设计原理 : 设计思路完全改变, 和HashMap是一样的; 那怎么保证线程安全和并发量的? synchronized? Lock接口? CAS?; 查看源码,初始化是通过CAS实现的, put 是 sync
- 但是它是怎么保证线程安全的呢?
  1. 初始化采用 cas 机制
  2. put 的时候, 如果当前位置为 null, 采用 cas 机制
  3. 如果不为 null, 则使用同步关键字

## 五 : ConcurrentSkipListMap

特点 : **有序链表**实现, **无锁**实现; value 不能为空; 层级越高跳跃性越大, 数据越少, 查询理论变快;

和 HashMap 的结构完全不一样, 跳表中包含了一个 index, 在 index 中存储 Node 节点的引用

```java
class Index {
    Node node;
    Index right; //先比对入口索引, 如果大于入口索引,则向右进行比对
    Index down;  //如果小于右边的索引, 则向下比对
}
class Node {
    String key;
    String value;
    Node next;
}
```

插入 Node 节点的时候, 随机创建索引(创建一个随机数, 如果是偶数, 就创建索引); 如果数据量大, 索引量大也会导致查询效率降低, 这时候引入索引分级的概念

索引分级: 根据生成的随机数的**二进制数的连续为 1 的数量**来确定 level ; 每层的元素, headIndex 固定为所有 node 中最小的

查找数据时, 按照**先从左到右, 后从上到下**的顺序查找; 时间复杂度O(log n), 空间复杂度O(n); 性能提升思路就是常说的空间换时间, 数据库索引类似的概念, skiplist 在很多开源组件中有使用 (level DB, Redis)

关于线程安全方面, 依然还是采用 CAS 机制